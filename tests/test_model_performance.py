import joblib
import numpy as np
from sklearn.metrics import classification_report, confusion_matrix
import pandas as pd

def test_model_performance():
    print("üß™ TEST DES PERFORMANCES DU MOD√àLE")
    print("=" * 50)
    
    # Charger le mod√®le et les m√©triques
    model = joblib.load('models/trained/best_sentiment_model.joblib')
    vectorizer = joblib.load('models/trained/tfidf_vectorizer.joblib')
    metrics = joblib.load('models/trained/model_metrics.joblib')
    
    print("‚úÖ Mod√®les charg√©s avec succ√®s")
    print(f"ü§ñ Mod√®le: {type(model).__name__}")
    print(f"üî§ Vectoriseur: {type(vectorizer).__name__}")
    
    # Afficher les m√©triques
    print("\nüìä M√âTRIQUES D'ENTRA√éNEMENT:")
    for key, value in metrics.items():
        if isinstance(value, (int, float)):
            print(f"   {key}: {value:.4f}")
    
    # Charger les donn√©es de test
    try:
        test_data = pd.read_csv('data/processed/test.csv')
        print(f"\nüìÅ Donn√©es de test: {len(test_data)} √©chantillons")
        
        # Pr√©parer les donn√©es
        X_test = vectorizer.transform(test_data['text'])
        y_test = test_data['label']
        
        # Pr√©dictions
        y_pred = model.predict(X_test)
        
        # M√©triques de test
        from sklearn.metrics import accuracy_score, f1_score
        accuracy = accuracy_score(y_test, y_pred)
        f1 = f1_score(y_test, y_pred, average='weighted')
        
        print(f"üéØ Accuracy sur test set: {accuracy:.4f}")
        print(f"üìà F1-score sur test set: {f1:.4f}")
        
        # Seuils de performance
        if accuracy >= 0.75:
            print("‚úÖ PERFORMANCE: Acceptable")
        elif accuracy >= 0.80:
            print("‚úÖ PERFORMANCE: Bonne")
        else:
            print("‚ö†Ô∏è  PERFORMANCE: √Ä am√©liorer")
            
    except Exception as e:
        print(f"‚ùå Erreur lors du test: {e}")

if __name__ == "__main__":
    test_model_performance()
